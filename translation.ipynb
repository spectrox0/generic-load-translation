{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine,text\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() \n",
    "DATABASE_URL=os.getenv('DB_URL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(url=DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sqlalchemy.engine.base.Connection object at 0x11866d310>\n"
     ]
    }
   ],
   "source": [
    "# Test connection\n",
    "connection = engine.connect()\n",
    "print(connection)\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './translation.xlsx'\n",
    "translations_df = pd.read_excel(file_path)\n",
    "\n",
    "# Convertir los nombres de las columnas a minúsculas\n",
    "translations_df.columns = [col.lower() for col in translations_df.columns]\n",
    "translations_df = translations_df.drop_duplicates(subset=['token'], keep='last')\n",
    "\n",
    "\n",
    "# Verifica que las columnas estén bien definidas\n",
    "print(translations_df.columns)  \n",
    "print(translations_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los grupos existentes en tr_group\n",
    "def get_existing_groups():\n",
    "    with engine.connect() as connection:\n",
    "        existing_groups = {}\n",
    "        try:\n",
    "            result = connection.execute(text(\"SELECT group_id, group_name FROM tr_group\"))\n",
    "            for row in result:\n",
    "                existing_groups[row[1]] = row[0]\n",
    "            return existing_groups\n",
    "        except Exception as e:\n",
    "            print(\"Error al obtener los grupos existentes en tr_group:\", e)\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_existing_translations():\n",
    "    with engine.connect() as connection:\n",
    "        existing_translations = {}\n",
    "        try:\n",
    "            result = connection.execute(text(\"SELECT tr_group_id, language_id, translation_key FROM tr_translation\"))\n",
    "            for row in result:\n",
    "                existing_translations[(row[0], row[1], row[2])] = True\n",
    "            return existing_translations\n",
    "        except Exception as e:\n",
    "            print(\"Error al obtener las traducciones existentes en tr_translation:\", e)\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuevos grupos a insertar: set()\n",
      "Mapa de nuevos grupos: {}\n"
     ]
    }
   ],
   "source": [
    "existing_groups = get_existing_groups()\n",
    "\n",
    "# Obtener los prefijos de los tokens del CSV\n",
    "token_prefixes = set(row['token'].split('.')[0] for _, row in translations_df.iterrows())\n",
    "\n",
    "# Determinar los nuevos grupos que no están en tr_group\n",
    "new_groups = token_prefixes - set(existing_groups.keys())\n",
    "print(\"Nuevos grupos a insertar:\", new_groups)\n",
    "\n",
    "# Asignar IDs a los nuevos grupos\n",
    "if existing_groups:\n",
    "    max_existing_id = max(existing_groups.values())\n",
    "else:\n",
    "    max_existing_id = 0\n",
    "\n",
    "new_group_map = {group: max_existing_id + 1 + i for i, group in enumerate(new_groups)}\n",
    "print(\"Mapa de nuevos grupos:\", new_group_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "sql_statements_group = []\n",
    "for group_name, group_id in new_group_map.items():\n",
    "    sql = f\"\"\"\n",
    "    INSERT INTO tr_group (group_id, group_name, group_enabled, date_created, date_modified)\n",
    "    VALUES ({group_id}, '{group_name}', 1, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);\n",
    "    \"\"\"\n",
    "    sql_statements_group.append(sql)\n",
    "\n",
    "print(sql_statements_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consultas de inserción ejecutadas con éxito.\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar las consultas\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        for sql in sql_statements_group:\n",
    "            connection.execute(text(sql))\n",
    "        connection.commit()\n",
    "        print(\"Consultas de inserción ejecutadas con éxito.\")\n",
    "except Exception as e:\n",
    "    print(\"Error al ejecutar consultas de inserción:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_group_map.update(existing_groups)\n",
    "print(\"Mapa de grupos actualizado:\", new_group_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapa de idiomas: {'es': 1, 'en': 2, 'ht': 3, 'sw': 4, 'ara': 5, 'fr': 6}\n"
     ]
    }
   ],
   "source": [
    "# Mapeo de language_name a language_id\n",
    "csv_to_locale = {\n",
    "    'en': 'english',\n",
    "    'es': 'spanish',\n",
    "    'ht' : 'kreyol',\n",
    "    'sw': 'swahili',\n",
    "    'ara':'arab',\n",
    "    'fr': 'french'\n",
    "}\n",
    "\n",
    "language_map = {}\n",
    "sql = \"\"\"\n",
    "SELECT language_id, language_locale FROM tr_language;\n",
    "\"\"\"\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(sql))\n",
    "        for row in result:\n",
    "            language_map[row[1]] = row[0]\n",
    "        print(\"Mapa de idiomas:\", language_map)\n",
    "except Exception as e:\n",
    "    print(\"Error al obtener el mapa de idiomas:\", e)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "def normalize_and_compare(text1:str, text2:str) -> bool:\n",
    "    def normalize_text(text:str):\n",
    "        # Normaliza el texto usando la forma NFC\n",
    "        normalized = unicodedata.normalize('NFC', text)\n",
    "        # Elimina los espacios en blanco al inicio y al final\n",
    "        stripped = normalized.strip()\n",
    "        # Convierte el texto a minúsculas\n",
    "        lowercased = stripped.lower()\n",
    "        return lowercased\n",
    "    \n",
    "    normalized_text1 = normalize_text(text1)\n",
    "    normalized_text2 = normalize_text(text2)\n",
    "    \n",
    "    return normalized_text1 == normalized_text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total consultas de inserción en tr_translation: 0\n",
      "Consultas de inserción en tr_translation ejecutadas con éxito.\n"
     ]
    }
   ],
   "source": [
    "# Generar consultas SQL para tr_translation verificando la existencia\n",
    "sql_statements_translation = []\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        for _, row in translations_df.iterrows():\n",
    "            for locale, column_name in csv_to_locale.items():\n",
    "                language_id = language_map.get(locale)\n",
    "                if language_id and not pd.isna(row[column_name]):\n",
    "                    token_parts = row['token'].split('.')\n",
    "                    group_name = token_parts[0]\n",
    "                    translation_item = '.'.join(token_parts[1:])\n",
    "                    group_id = new_group_map.get(group_name)\n",
    "\n",
    "                    if group_id:\n",
    "                        translation_text_raw = row[column_name]\n",
    "                        translation_text = translation_text_raw.replace(\"'\", \"''\")\n",
    "                        # Verificar si la traducción ya existe\n",
    "                        check_sql = f\"\"\"\n",
    "                        SELECT translation_text FROM tr_translation\n",
    "                        WHERE language_id = {language_id} AND group_id = {group_id} AND translation_item = '{translation_item}';\n",
    "                        \"\"\"\n",
    "                        result = connection.execute(text(check_sql))\n",
    "                        existing_translation = result.fetchone()\n",
    "                        if existing_translation is not None and existing_translation[0] is not None:\n",
    "                            # Si no existe, agregar la consulta de inserción\n",
    "                            existing_text = existing_translation[0]\n",
    "\n",
    "                            if normalize_and_compare(translation_text_raw, existing_text) is False:\n",
    "                                # print(\"translation text\",translation_text_raw)\n",
    "                                # print(\"existing text\",existing_text)\n",
    "                                # print(\"translation item\",translation_item)\n",
    "                                # print(\"language id\",language_id)\n",
    "                                # print(\"group id\",group_id)\n",
    "                                update_sql = f\"\"\"\n",
    "                                UPDATE tr_translation\n",
    "                                SET translation_text = '{translation_text}', date_modified = CURRENT_TIMESTAMP\n",
    "                                WHERE language_id = {language_id} AND group_id = {group_id} AND translation_item = '{translation_item} AND translation_text = '{existing_text}';\n",
    "                                \"\"\"\n",
    "                                sql_statements_translation.append(update_sql)\n",
    "                        else :\n",
    "                            insert_sql = f\"\"\"\n",
    "                            INSERT INTO tr_translation (language_id, group_id, translation_item, translation_text, translation_enabled, date_created, date_modified)\n",
    "                            VALUES ({language_id}, {group_id}, '{translation_item}', '{translation_text}', 1, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);\n",
    "                            \"\"\"\n",
    "                            sql_statements_translation.append(insert_sql)\n",
    "        # Ejecutar las consultas de inserción\n",
    "        print(\"Total consultas de inserción en tr_translation:\", len(sql_statements_translation))\n",
    "        for sql in sql_statements_translation:\n",
    "            print(sql)\n",
    "            connection.execute(text(sql))\n",
    "        connection.commit()\n",
    "        print(\"Consultas de inserción en tr_translation ejecutadas con éxito.\")\n",
    "except Exception as e:\n",
    "    print(\"Error al verificar o insertar en tr_translation:\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
